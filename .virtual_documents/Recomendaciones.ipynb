





import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns
import numpy as np
import operator
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder
from category_encoders import TargetEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from xgboost import XGBClassifier
from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, confusion_matrix, classification_report
from sklearn.model_selection import RandomizedSearchCV
import scipy.stats as stats





df_tree = pd.read_csv("datasets/category_tree.csv")
df_events = pd.read_csv("datasets/events.csv")
df_item_prop1 = pd.read_csv("datasets/item_properties_part1.csv")
df_item_prop2 = pd.read_csv("datasets/item_properties_part2.csv")





df_items = pd.concat([df_item_prop1, df_item_prop2])





df_events.describe()


df_events[df_events.transactionid.notnull()].event.unique()





len(df_events.itemid.unique())





df_events['event'].value_counts()





df_items.head()


df_tree.head()


df_items.isnull().sum()


df_tree.isnull().sum()





customers_that_bought = df_events[df_events.transactionid.notnull()].visitorid.unique()
customers_that_bought.size


customers_that_not_bought = df_events[df_events.transactionid.isnull()].visitorid.unique()
customers_that_not_bought.size


total = df_events['visitorid'].unique().size
percentage_bought = (customers_that_bought.size / total) * 100
percentage_not_bought = 100 - percentage_bought

plt.figure(figsize=(10,6))
plt.pie([percentage_bought, percentage_not_bought], labels=['Compraron', 'No Compraron'], autopct='%1.1f%%')
plt.title("Usuarios totales de la plataforma")
plt.axis('equal')
plt.show()





events_info = df_events['event'].value_counts()
plt.figure(figsize=(10,6))
plt.pie(events_info.values, labels=events_info.index, autopct='%1.1f%%')
plt.title("Eventos totales en la plataforma")
plt.show()





df_events['timestamp'] = pd.to_datetime(df_events['timestamp'], unit='ms')
monthly = df_events.groupby(df_events['timestamp'].dt.to_period('M')).size()

plt.figure(figsize=(10,6))
monthly.plot(kind='line', marker='o')
plt.title('Interacciones por mes')
plt.xlabel('Mes')
plt.ylabel('Numero de interacciones')
plt.grid(True)
plt.show()





add_to_cart_customers = df_events[df_events['event'] == 'addtocart']['visitorid'].nunique()
cart_and_buy_customers = df_events[(df_events['event'] == 'addtocart') & (df_events['visitorid'].isin(customers_that_bought))]['visitorid'].nunique()


cart_buy_data = pd.DataFrame({
    'Evento': ['Agregan al carrito', 'Agregan al carrito y compran'],
    'Cantidad': [add_to_cart_customers, cart_and_buy_customers]
})


plt.figure(figsize=(10,6))
sns.barplot(x='Evento', y='Cantidad', data=cart_buy_data)
plt.title('Relacion entre agregar al carrito y comprar')
plt.xlabel('Evento')
plt.ylabel('Numero de usuarios')
plt.show()






times_add_cart = df_events[df_events['event'] == 'addtocart'].groupby('itemid').size().reset_index(name='cart_count')
times_bought = df_events[df_events['event'] == 'transaction'].groupby('itemid').size().reset_index(name='purchase_count')

cart_purchase = pd.merge(times_add_cart, times_bought, on='itemid', how='left').fillna(0)
cart_purchase['purchase_to_cart_ratio'] = cart_purchase['purchase_count'] / cart_purchase['cart_count']

avg_add_bought = cart_purchase['purchase_to_cart_ratio'].mean()

plt.figure(figsize=(10,6))
sns.histplot(cart_purchase['purchase_to_cart_ratio'], bins=50, kde=True)
plt.title(f'Promedio de la relacion agregar al carro y comprar: {avg_add_bought:.2f}')
plt.xlabel('Relacion: agrega al carro - compra')
plt.xlim(0, 2)
plt.ylabel('Numero de productos')
plt.show()






product_event_counts = df_events.groupby(['itemid', 'event']).size().unstack()
product_event_counts.plot(kind='scatter', x='view', y='transaction', title='Relacion vista-compra')





view_events = df_events[df_events['event'] == 'view']
cart_events = df_events[df_events['event'] == 'addtocart']
purchase_events = df_events[df_events['event'] == 'transaction']

most_viewed = view_events['itemid'].value_counts().head(10)
most_cart = cart_events['itemid'].value_counts().head(10)
most_purchased = purchase_events['itemid'].value_counts().head(10)


plt.figure(figsize=(10, 5))
sns.barplot(x=most_viewed.index, y=most_viewed.values)
plt.title('Productos mas vistos')
plt.xlabel('id de producto')
plt.ylabel('numero de vistas')
plt.show()


plt.figure(figsize=(10,6))
sns.barplot(x=most_cart.index, y=most_cart.values)
plt.title('Productos mas agregados al carro')
plt.xlabel('id de producto')
plt.ylabel('numero de agregado al carro')
plt.show()


plt.figure(figsize=(10,6))
sns.barplot(x=most_purchased.index, y=most_purchased.values)
plt.title('Productos mas comprados')
plt.xlabel('id de producto')
plt.ylabel('numero de compras')
plt.show()





set_viewed = set(most_viewed.index)
set_cart = set(most_cart.index)
set_purchased = set(most_purchased.index)

viewed_and_cart = set_viewed.intersection(set_cart)
viewed_and_purchased = set_viewed.intersection(set_purchased)
cart_and_purchased = set_cart.intersection(set_purchased)

print(f"Los productos mas vistos y añadidos al carro {viewed_and_cart}")
print(f"Los productos mas vistos y comprados: {viewed_and_purchased}")
print(f"Los productos mas agregados al carro y comprados: {cart_and_purchased}")





user_interactions = df_events.groupby('visitorid').size().reset_index(name='total_interactions')
most_active_users = user_interactions.sort_values(by='total_interactions', ascending=False).head(10)

plt.figure(figsize=(10,6))
plt.bar(most_active_users['visitorid'].astype(str), most_active_users['total_interactions'])
plt.title('Usuarios con mas interacciones')
plt.xlabel('Id de usuario')
plt.ylabel('numero de interacciones')
plt.xticks(rotation=90)





purchasing_users = df_events[df_events['event'] == 'transaction']
#customers_that_bought
top_buyers = purchasing_users.groupby('visitorid').size().reset_index(name='total_purchases')
top_buyers = top_buyers.sort_values(by='total_purchases', ascending=False).head(10)

plt.figure(figsize=(10,6))
plt.bar(top_buyers['visitorid'].astype(str), top_buyers['total_purchases'])
plt.title('Usuarios que mas compran')
plt.xlabel('ID de usuario')
plt.ylabel('Total de compras')
plt.xticks(rotation=90)
plt.show()








df_events['itemid'].value_counts()


df_events['visitorid'].value_counts()





category_info = df_items[df_items['property'] == 'categoryid'][['itemid', 'value']]
category_info = category_info.rename(columns={'value': 'categoryid'})
events_with_category = df_events.merge(category_info, on='itemid', how='left')
viewed_events = events_with_category[events_with_category['event'] == 'view']
    
num_categories_dict = viewed_events.groupby('visitorid')['categoryid'].nunique().to_dict()
addtocart_counts = df_events[df_events.event == 'addtocart'].groupby('visitorid').size().to_dict()
favorite_category_dict = viewed_events.groupby('visitorid')['categoryid'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan).to_dict()


grouped_events = df_events.groupby('visitorid')


import time
import pandas as pd
import numpy as np

def features_engineering(df):
    df_result = []
    count = 0
    
    for customer_id in df:
        if count % 100000 == 0:
            print("Llevamos 100k")
        count += 1
        
        # Medir tiempo total del proceso de cada cliente
        start_time_total = time.time()
        
        # Filtrar eventos del cliente
        start_time = time.time()
        df_customer_events = grouped_events.get_group(customer_id) if customer_id in grouped_events.groups else pd.DataFrame()        
        print(f"Tiempo para filtrar eventos del cliente: {time.time() - start_time:.4f} segundos")
        
        df_customer = [customer_id]

        # Productos visualizados
        start_time = time.time()
        df_customer.append(df_customer_events[df_customer_events.event == 'view'].itemid.nunique())
        print(f"Tiempo para contar productos visualizados: {time.time() - start_time:.4f} segundos")

        # Visualizaciones totales
        start_time = time.time()
        df_customer.append(df_customer_events[df_customer_events.event == 'view'].event.count())
        print(f"Tiempo para contar visualizaciones totales: {time.time() - start_time:.4f} segundos")

        # Productos comprados
        start_time = time.time()
        df_customer.append(df_customer_events[df_customer_events.event == 'transaction'].itemid.nunique())
        print(f"Tiempo para contar productos comprados: {time.time() - start_time:.4f} segundos")

        # Compras totales
        start_time = time.time()
        df_customer.append(df_customer_events[df_customer_events.event == 'transaction'].event.count())
        print(f"Tiempo para contar compras totales: {time.time() - start_time:.4f} segundos")

        # Promedio de vistas por producto
        start_time = time.time()
        avg_views = df_customer_events[df_customer_events.event == 'view'].itemid.value_counts().mean()
        df_customer.append(avg_views)
        print(f"Tiempo para calcular promedio de vistas: {time.time() - start_time:.4f} segundos")

        # Categorías vistas y favorita
        start_time = time.time()
        df_customer.append(num_categories_dict.get(customer_id, 0))
        df_customer.append(favorite_category_dict.get(customer_id, np.nan))
        print(f"Tiempo para obtener categorías: {time.time() - start_time:.4f} segundos")

        # Tasa de conversión
        start_time = time.time()
        conversion_rate = df_customer[4] / df_customer[2] if df_customer[2] > 0 else 0
        df_customer.append(conversion_rate)
        print(f"Tiempo para calcular tasa de conversión: {time.time() - start_time:.4f} segundos")

        # Agregados al carrito
        start_time = time.time()
        df_customer.append(addtocart_counts.get(customer_id, 0))
        print(f"Tiempo para contar agregados al carrito: {time.time() - start_time:.4f} segundos")

        # Contar sesiones
        start_time = time.time()
        df_customer_events = df_customer_events.sort_values(by='timestamp')
        df_customer_events['session_id'] = (df_customer_events['timestamp'].diff() > pd.Timedelta(seconds=3600)).cumsum()
        df_customer.append(df_customer_events['session_id'].nunique())
        print(f"Tiempo para contar sesiones: {time.time() - start_time:.4f} segundos")

        df_result.append(df_customer)

        # Imprimir tiempo total para cada cliente
        print(f"Tiempo total para cliente {customer_id}: {time.time() - start_time_total:.4f} segundos\n")

    return pd.DataFrame(df_result, columns=[
        'visitorid', 'n_items_viewed', 'view_count', 'n_items_bought', 'n_purchases', 
        'avg_views_per_product', 'num_categories_viewed', 
        'favorite_category', 'view_to_bought', 'n_items_cart', 'session_count'
    ])



def features_engineering(df):
    df_result = []
    count  = 0
    
    for customer_id in df:
        if count % 100000 == 0:
            print("Llevamos 100k")
        count += 1
        df_customer_events = grouped_events.get_group(customer_id) if customer_id in grouped_events.groups else pd.DataFrame()
        df_customer = []
        df_customer.append(customer_id)
        
        # Cuántos productos visualizó
        df_customer.append(df_customer_events[df_customer_events.event == 'view'].itemid.nunique())
        
        # Cuántas visualizaciones
        df_customer.append(df_customer_events[df_customer_events.event == 'view'].event.count())

        # Cuántos productos compró
        df_customer.append(df_customer_events[df_customer_events.event == 'transaction'].itemid.nunique())
        
        # Cuántas compras realizadas
        df_customer.append(df_customer_events[df_customer_events.event == 'transaction'].event.count())
        
        # Promedio de vistas por producto
        avg_views = df_customer_events[df_customer_events.event == 'view'].itemid.value_counts().mean()
        df_customer.append(avg_views)
        
        # Categorías vistas y la favorita
        df_customer.append(num_categories_dict.get(customer_id, 0))
        df_customer.append(favorite_category_dict.get(customer_id, np.nan))
        
        # Tasa de conversión
        conversion_rate = df_customer[4] / df_customer[2] if df_customer[2] > 0 else 0
        df_customer.append(conversion_rate)
        
        # Agregados al carrito
        df_customer.append(addtocart_counts.get(customer_id, 0))

        #Tasa de conversion carrito
        conversion_rate_cart = df_customer[9] / df_customer[2] if df_customer[2] > 0 else 0
        df_customer.append(conversion_rate)
        
        # Contar sesiones
        df_customer_events = df_customer_events.sort_values(by='timestamp')
        df_customer_events['session_id'] = (df_customer_events['timestamp'].diff() > pd.Timedelta(seconds=3600)).cumsum()
        df_customer.append(df_customer_events['session_id'].nunique())
        
        df_result.append(df_customer)
    return pd.DataFrame(df_result, columns=[
        'visitorid', 'n_items_viewed', 'view_count', 'n_items_bought', 'n_purchases', 
        'avg_views_per_product', 'num_categories_viewed', 
        'favorite_category', 'view_to_bought', 'n_items_cart', 'view_to_cart','session_count'
    ])



df_new_features_bought = features_engineering(customers_that_bought)
print(len(customers_that_bought), len(df_new_features_bought))


df_new_features_dont_bought = features_engineering(customers_that_not_bought[:100000])
print(len(customers_that_not_bought), len(df_new_features_dont_bought))





df_merged = pd.concat([df_new_features_bought, df_new_features_dont_bought], ignore_index=True)
df_merged['purchased'] = df_merged['n_purchases'].apply(lambda x: 1 if x > 0 else 0)









scaler = MinMaxScaler()
df_events['timestamp_normalized'] = scaler.fit_transform(df_events[['timestamp']])





scaler = MinMaxScaler()
df_merged[['n_items_viewed', 'view_count', 'n_items_bought', 
    'n_purchases', 'avg_views_per_product', 
    'n_items_cart', 'view_to_cart', 'session_count']] = scaler.fit_transform(
        df_merged[['n_items_viewed', 'view_count', 'n_items_bought', 
            'n_purchases', 'avg_views_per_product', 
            'n_items_cart', 'view_to_cart', 'session_count']])





standard_scaler = StandardScaler()
df_merged[['view_to_bought', 'num_categories_viewed']] = standard_scaler.fit_transform(
                                df_merged[['view_to_bought', 'num_categories_viewed']])





correlation_matrix = df_merged.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.show()





df_merged = df_merged.drop(['n_items_viewed', 'n_items_bought'], axis=1)





all(df_merged['favorite_category'].astype(str).str.isdigit())





non_digit_values = df_merged[~df_merged['favorite_category'].astype(str).str.isdigit()]['favorite_category']
print(non_digit_values.unique())
contains_negative_one = (-1 in df_merged['favorite_category'].values)
print(contains_negative_one)





df_merged['favorite_category'] = df_merged['favorite_category'].fillna('-1')





encoder = OneHotEncoder(sparse_output=False)
encoded_categories = encoder.fit_transform(df_merged[['favorite_category']])
df_encoded = pd.DataFrame(encoded_categories, columns=encoder.get_feature_names_out(['favorite_category']))
print(df_encoded.shape)
print(df_merged.shape)





label_encoder = LabelEncoder()
df_merged['favorite_category'] = label_encoder.fit_transform(df_merged['favorite_category'])
print(df_merged.head())





df_merged[['favorite_category']] = scaler.fit_transform(
        df_merged[['favorite_category']])
print(df_merged.head())


#X = df_merged.drop(columns=['purchased', 'visitorid'])
#y = df_merged['purchased']





smote = SMOTE(sampling_strategy='auto', random_state=42)





nan_counts = df_merged.isna().sum()
print(nan_counts)





#'reg_alpha': [0, 0.01, 0.1],
#'reg_lambda': [1, 1.5, 2]
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [4, 6, 8, 10],
    'learning_rate': [0.001, 0.005, 0.01],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.5, 0.7, 0.9],
    'min_child_weight': [1, 5, 10],
    'gamma': [0, 0.1, 0.3]
}





X_engagement = df_merged[['view_count', 'avg_views_per_product', 'num_categories_viewed', 'session_count', 
                   'favorite_category']]
y_engagement = (df_merged['n_items_cart'] > 0).astype(int)

X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(X_engagement, y_engagement, test_size=0.3, random_state=42)
no_na_X_train_eng = X_train_eng.dropna()
y_train_eng_dropped = y_train_eng[no_na_X_train_eng.index]
X_resampled, y_resampled = smote.fit_resample(no_na_X_train_eng, y_train_eng_dropped)
print(y_resampled.value_counts())
print(X_resampled.shape)


grid_search_engagement = GridSearchCV(estimator=XGBClassifier(random_state=42), 
                           param_grid=param_grid, 
                           cv=5, 
                           scoring='f1', 
                           n_jobs=-1)
grid_search_engagement.fit(X_resampled, y_resampled)


best_model_engagement = grid_search_engagement.best_estimator_
print("Best parameters found: ", grid_search.best_params_)





y_probs = best_model_engagement.predict_proba(X_test_eng)[:, 1]

fpr, tpr, _ = roc_curve(y_test_eng, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

print(f"AUC-ROC: {roc_auc}")






y_pred_engagement = best_model_engagement.predict(X_test_eng)
print("Precision: ", precision_score(y_test_eng, y_pred_engagement))
print("Accuracy: ", accuracy_score(y_test_eng, y_pred_engagement))
print("Recall: ", recall_score(y_test_eng, y_pred_engagement))
print("F1-score: ", f1_score(y_test_eng, y_pred_engagement))





cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cross_val_results = cross_val_score(best_model_engagement, X_engagement, y_engagement, cv=cv, scoring='accuracy', n_jobs=-1)

print(f"Cross-Validation Accuracy: {cross_val_results.mean():.4f} ± {cross_val_results.std():.4f}")








df_conversion = df_merged[df_merged['n_items_cart'] > 0]
X_conversion = df_conversion[['n_items_cart', 'session_count', 'num_categories_viewed', 
                              'favorite_category']]
y_conversion = df_conversion['purchased']



X_train_conv, X_test_conv, y_train_conv, y_test_conv = train_test_split(X_conversion, y_conversion, test_size=0.2, random_state=42)
no_nan_X_train_conv = X_train_conv.dropna()
no_nan_y_tain_conv = y_train_conv[no_nan_X_train_conv.index]
X_resampled_conv, y_resampled_conv = smote.fit_resample(no_nan_X_train_conv, no_nan_y_tain_conv)


grid_search_conv = GridSearchCV(estimator=XGBClassifier(random_state=42), 
                           param_grid=param_grid, 
                           cv=5, 
                           scoring='f1', 
                           n_jobs=-1)
grid_search_conv.fit(X_resampled_conv, y_resampled_conv)


best_model_conv = grid_search_conv.best_estimator_
print("Best parameters found: ", grid_search_conv.best_params_)


# Modelo simple
#conversion_model = XGBClassifier(random_state=42)
#conversion_model.fit(X_resampled_conv, y_resampled_conv)





y_probs = best_model_conv.predict_proba(X_test_conv)[:, 1]

fpr, tpr, _ = roc_curve(y_test_conv, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

print(f"AUC-ROC: {roc_auc}")





y_pred_conv = best_model_conv.predict(X_test_conv)
print("Precision: ", precision_score(y_test_conv, y_pred_conv))
print("Accuracy: ", accuracy_score(y_test_conv, y_pred_conv))
print("Recall: ", recall_score(y_test_conv, y_pred_conv))
print("F1-score: ", f1_score(y_test_conv, y_pred_conv))





cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cross_val_results = cross_val_score(best_model_conv, X_conversion, y_conversion, cv=cv, scoring='accuracy', n_jobs=-1)

print(f"Cross-Validation Accuracy: {cross_val_results.mean():.4f} ± {cross_val_results.std():.4f}")





engagement_probabilities = best_model_engagement.predict_proba(X_engagement)[:, 1]
df_engagement = X_engagement.copy()
df_engagement['engagement_probability'] = engagement_probabilities

conversion_probabilities = best_model_conv.predict_proba(X_conversion)[:, 1]
df_conversion = X_conversion.copy()
df_conversion['conversion_probability'] = conversion_probabilities
df_conversion = df_conversion.merge(
    df_engagement[['engagement_probability']], 
    left_index=True, 
    right_index=True, 
    how='left'
)


high_engagement_threshold = 0.6
high_conversion_threshold = 0.6

high_engage_convert = df_conversion[
    (df_conversion['engagement_probability'] >= high_engagement_threshold) & 
    (df_conversion['conversion_probability'] >= high_conversion_threshold)
]

low_engage_high_convert = df_conversion[
    (df_conversion['engagement_probability'] < high_engagement_threshold) & 
    (df_conversion['conversion_probability'] >= high_conversion_threshold)
]

high_engage_low_convert = df_conversion[
    (df_conversion['engagement_probability'] >= high_engagement_threshold) & 
    (df_conversion['conversion_probability'] < high_conversion_threshold)
]

low_engage_low_convert = df_conversion[
    (df_conversion['engagement_probability'] < high_engagement_threshold) & 
    (df_conversion['conversion_probability'] < high_conversion_threshold)
]





engagement_features = X_train_eng.columns.tolist()

eng_feature_importance = pd.DataFrame({
    'Feature': engagement_features,
    'Importance': best_model_engagement.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("Feature Importance:")
print(eng_feature_importance)

# Visualización
plt.figure(figsize=(10, 6))
plt.barh(eng_feature_importance['Feature'], eng_feature_importance['Importance'], color='skyblue')
plt.title("Feature Importance - XGBoost Engagement Model")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.show()


correlation = df_merged['view_to_cart'].corr(df_merged['purchased'])
correlation_2 = df_merged['n_items_cart'].corr(df_merged['purchased'])
print(f"Correlacion: views ratio a purchase: {correlation}")
print(f"Correlacion n items cart a purchase: {correlation_2}")



conversion_features = X_train_conv.columns.tolist()
print(best_model_conv.feature_importances_)
print(conversion_features)

conv_feature_importance = pd.DataFrame({
    'Feature': conversion_features,
    'Importance': best_model_conv.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("Feature Importance:")
print(conv_feature_importance)

plt.figure(figsize=(10, 6))
plt.barh(conv_feature_importance['Feature'], conv_feature_importance['Importance'], color='skyblue')
plt.title("Feature Importance - XGBoost Conversion Model")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.show()


df_engagement['segment'] = pd.cut(
    df_engagement['engagement_probability'], 
    bins=[0, 0.3, 0.7, 1.0], 
    labels=['Low Engagement', 'Medium Engagement', 'High Engagement']
)

segment_summary = df_engagement.groupby('segment', observed=True).mean()
print("Engagement Segmentation Summary:")
print(segment_summary)






df_engagement['engagement_probability'] = best_model_engagement.predict_proba(X_engagement)[:, 1]
engaged_users = df_engagement[df_engagement['engagement_probability'] > 0.7]

common_indices = engaged_users.index.intersection(X_conversion.index)
engaged_users = engaged_users.loc[common_indices]
new_X_conversion = X_conversion.loc[common_indices]
engaged_users['conversion_probability'] = best_model_conv.predict_proba(new_X_conversion)[:, 1]
# Desnormalizar con inverse_transform
df_merged['favorite_category_desnormalizado'] = scaler.inverse_transform(df_merged[['favorite_category']])
def recommend_products(user_id, user_data, top_n=5):
    favorite_category = str(
        user_data.loc[user_data['visitorid'] == user_id, 'favorite_category_desnormalizado'].iloc[0]
    ).split('.')[0]
    print(f"Fav: {favorite_category}")
    
    category_items = df_items[
        (df_items['value'] == favorite_category) & 
        (df_items['property'] == 'categoryid')
    ].drop_duplicates(subset='itemid')
    
    category_items_ids = category_items['itemid'].unique()
    filtered_conversion = df_conversion[df_conversion.index.isin(category_items_ids)]

    filtered_conversion = filtered_conversion.merge(
        engaged_users[['engagement_probability']], 
        left_index=True, 
        right_index=True, 
        how='left'
    )

    filtered_conversion['score'] = (
        0.7 * filtered_conversion['conversion_probability']
        #0.3 * filtered_conversion['engagement_probability']
    )

    top_recommendations = filtered_conversion.sort_values('score', ascending=False).head(top_n)

    return top_recommendations.index.tolist()

recommendations = recommend_products(user_id=552148, user_data=df_merged, top_n=5)
print("Recommended Products:", recommendations)


engagement_rate = len(engaged_users) / len(df_engagement)
print(f"Engagement Realizado: {engagement_rate:.2%}")


buy_users = len(df_conversion['conversion_probability'] > 0)
conversion_rate = buy_users / len(df_engagement)
print(f"Conversion Realizada: {conversion_rate:.2%}")

